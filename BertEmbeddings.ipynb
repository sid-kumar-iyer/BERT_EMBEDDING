{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvwrZWTh47zQ"
   },
   "outputs": [],
   "source": [
    "# !pip install bert-embedding\n",
    "# !pip install mxnet-cu80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFFkWQP36HJi"
   },
   "source": [
    "UNCOMMENT THESE AND RUN\n",
    "\n",
    "THEN AFTER THAT COMMENT THESE AGAIN AND RESTART THE KERNEL AND RUN ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceMoylE7_r3O"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import cv2 as cv\n",
    "# import os\n",
    "import numpy as np\n",
    "import glob\n",
    "# from random import shuffle\n",
    "# from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import json\n",
    "from bert_embedding import BertEmbedding\n",
    "import mxnet as mx\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "T277o5d6_xqq",
    "outputId": "3c80b668-769f-4b3b-b812-d92be9e00105"
   },
   "outputs": [],
   "source": [
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oVSLJu__khe"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\",\"i am\",text)\n",
    "    text = re.sub(r\"i've\",\"i have\",text)\n",
    "    text = re.sub(r\"he's\",\"he is\",text)\n",
    "    text = re.sub(r\"she's\",\"she is\",text)\n",
    "    text = re.sub(r\"that's\",\"that is\",text)\n",
    "    text = re.sub(r\"that ' s\",\"that is\",text)\n",
    "    text = re.sub(r\"it's\",\"it is\",text)\n",
    "    text = re.sub(r\"that's\",\"that is\",text)\n",
    "    text = re.sub(r\"where's\",\"where is\",text)\n",
    "    text = re.sub(r\"what's\",\"what is\",text)\n",
    "    text = re.sub(r\"\\'ll\",\" will\",text) \n",
    "    text = re.sub(r\"\\'ve\",\" have\",text)\n",
    "    text = re.sub(r\"\\'re\",\" are\",text)\n",
    "    text = re.sub(r\"\\'d\",\" would\",text)  \n",
    "    text = re.sub(r\"won't\", \"will not\",text)\n",
    "    text = re.sub(r\"don't\", \"do not\",text)\n",
    "    text = re.sub(r\"can't\",\"can not\", text)\n",
    "    text = re.sub(r\"hadn't\",\"had not\", text)\n",
    "    text = re.sub(r\"didn't\",\"did not\", text)\n",
    "    text = re.sub(r\"wouldn't\",\"would not\", text)\n",
    "    text = re.sub(r\"weren't\",\"were not\", text)\n",
    "    text = re.sub(r\"shouldn't\",\"should not\", text)\n",
    "    text = re.sub(r\"doesn't\",\"does not\", text)\n",
    "    text = re.sub(r\"couldn't\",\"could not\", text)\n",
    "    text = re.sub(r\"isn't\",\"is not\", text)\n",
    "    text = re.sub(r\"hasn't\",\"has not\", text)\n",
    "    text = re.sub(r\"wasn't\",\"was not\", text)\n",
    "    text = re.sub(r\"haven't\",\"have not\", text)\n",
    "    text = re.sub(r\"didn't\",\"did not\", text)\n",
    "    text = re.sub(r\"wouldnt'\",\"would not\", text)\n",
    "#     text = re.sub(r\"shouldnt'\",\"should not\", text)\n",
    "#     text = re.sub(r\"doesnt'\",\"does not\", text)\n",
    "#     text = re.sub(r\"couldnt'\",\"could not\", text)\n",
    "#     text = re.sub(r\"isnt'\",\"is not\", text)\n",
    "#     text = re.sub(r\"wasn't\",\"was not\", text)\n",
    "#     text = re.sub(r\"havent'\",\"have not\", text)\n",
    "    text = re.sub(r\"aren't\",\"are not\", text)\n",
    "#     text = re.sub(r\"werent\",\"were not\", text)\n",
    "    text = re.sub(r\" em \",\" them \", text)\n",
    "    text = re.sub(r\" there's \",\" there is \", text)\n",
    "    text = re.sub(r\"let's\",\"let us\", text)\n",
    "    text = re.sub(r\" who's \",\" who is \", text)\n",
    "    text = re.sub(r\"\\'s\",\"\", text)\n",
    "    text = re.sub(r\"'\",\"\", text)\n",
    "# #     text = re.sub(r\"arent\",\"are not\", text)\n",
    "#     text = re.sub(r\"  \",\" \", text)\n",
    "#     text = re.sub(r\"[-?!@#$%^&*(~,;)+=_`<>{}.\\\"']\",\"\",text)\n",
    "#     pattern = r'[^a-zA-z0-9\\s]'\n",
    "#     text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7oyZhDVV__XV"
   },
   "source": [
    "USE THIS FOR 1024 EMBEDDING LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGHMZXjnwuLO"
   },
   "outputs": [],
   "source": [
    "final_emb={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "COtCF82XbfEe"
   },
   "outputs": [],
   "source": [
    "def create_embedding(data):\n",
    "  a=1\n",
    "  Participant_transcript=[rows[0].split(\"\\t\") for rows in data if len(rows)>0 if rows[0].split(\"\\t\")[2] == \"Participant\" ]\n",
    "#   print(Participant_transcript)\n",
    "  words=[clean_text(x[3].strip()).strip().split(\" \") for x in Participant_transcript]\n",
    "  while(a):\n",
    "    a=len([x.remove('') for x in words if '' in x])\n",
    "#   print(words[95])\n",
    "  for kk in words:\n",
    "        for ind,val in enumerate(kk):\n",
    "            if(val[0]=='<'and val[-1]=='>'):\n",
    "                kk[ind]=val[1:-1]\n",
    "            elif(val[0]=='<' ):\n",
    "                kk[ind]=val[1:]\n",
    "#   print(words)              \n",
    "  ctx = mx.gpu(0)\n",
    "  embedding= BertEmbedding(model='bert_24_1024_16', dataset_name='book_corpus_wiki_en_cased',ctx=ctx)\n",
    "  emb=[embedding(x) for x in words]\n",
    "#   cnt=0\n",
    "  for x in emb:\n",
    "    for i in range(len(x)):\n",
    "      if (x[i][0][0].isalpha()) and (x[i][0][0] not in final_emb):\n",
    "        final_emb[x[i][0][0]]=x[i][1][0].tolist()\n",
    "#     print(\"ln\",cnt)\n",
    "#     cnt+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gTZCNwev6SoK"
   },
   "source": [
    "CHANGE PATH TO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "colab_type": "code",
    "id": "rNRd4ZWH_3Fx",
    "outputId": "ddb54964-c62d-4c20-e087-e80a093cee33",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./trans/471_TRANSCRIPT.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in glob.glob(\"./trans/*RIPT.csv\"):#HERE\n",
    "    print(filename)\n",
    "    with open(filename,\"rt\") as f:\n",
    "      data=csv.reader(f)\n",
    "      create_embedding(data)\n",
    "#       a=1\n",
    "#       Participant_transcript=[rows[0].split(\"\\t\") for rows in data if len(rows)>0 if rows[0].split(\"\\t\")[2] == \"Participant\" ]\n",
    "#       print(Participant_transcript)\n",
    "#       words=[clean_text(x[3].strip()).split(\" \") for x in Participant_transcript]\n",
    "#       print(words)\n",
    "#       while(a):\n",
    "#         a=len([x.remove('') for x in words if '' in x])\n",
    "#       #   print(words[95])\n",
    "#       ctx = mx.gpu(0)\n",
    "#       embedding= BertEmbedding(model='bert_24_1024_16', dataset_name='book_corpus_wiki_en_cased',ctx=ctx)\n",
    "#       emb=[embedding(x) for x in words]\n",
    "# #         cnt=0\n",
    "#       for x in emb:\n",
    "#         for i in range(len(x)):\n",
    "#           if (x[i][0][0].isalpha()) and (x[i][0][0] not in final_emb):\n",
    "#             final_emb[x[i][0][0]]=x[i][1][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uv006QBx7pAt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxTL_foMEW6b"
   },
   "outputs": [],
   "source": [
    "with open('./Bert_1024B.json', 'w') as json_file:  \n",
    "    json.dump(final_emb, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1NFwBox3AaMC"
   },
   "source": [
    "Change path to save the json for  bert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HaxDbtQbJXZz",
    "outputId": "dea62865-4a91-49bf-fa14-6b36f8271e9c"
   },
   "outputs": [],
   "source": [
    "len(final_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ka2bAhoGHxD1"
   },
   "outputs": [],
   "source": [
    "# emb[0][0][1][0].shape#list[list(tuple[list[array\n",
    "final_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TH5GfSoaHz1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BertEmbeddings.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
